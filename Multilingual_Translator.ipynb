{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Installing Dependencies"
      ],
      "metadata": {
        "id": "9e6_sxJwYTPR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKuWOPDSYHBT",
        "outputId": "d7e185df-0dee-44d9-d519-b12e5229d836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m317.4/981.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers sentencepiece langdetect -q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `transformers`: For using MarianMT translation models\n",
        "\n",
        "### `sentencepiece`: needed by some translation tokenizers\n",
        "\n",
        "### `langdetect`: to automatically detect the input text's language"
      ],
      "metadata": {
        "id": "q71RP3_MYhM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "from langdetect import detect\n",
        "from transformers import MarianMTModel, MarianTokenizer\n"
      ],
      "metadata": {
        "id": "THNBYY7zYgVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input text\n",
        "text = \"à¤†à¤ª à¤•à¥ˆà¤¸à¥‡ à¤¹à¥ˆà¤‚?\"\n",
        "\n",
        "# Detect the source language\n",
        "src_lang = detect(text)\n",
        "print(\"Detected Language Code:\", src_lang)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQIGVa2mY_vN",
        "outputId": "74ed3174-5799-4f34-9a65-33257ca2768e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected Language Code: hi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### \"hi\" is the ISO 639-1 language code for Hindi."
      ],
      "metadata": {
        "id": "F5RIEtEdZ0pg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Language Setup and Supported Translation Models"
      ],
      "metadata": {
        "id": "_uaeLzd4o-lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianTokenizer, MarianMTModel\n",
        "\n",
        "# Language name to code mapping\n",
        "language_codes = {\n",
        "    \"English\": \"en\",\n",
        "    \"Hindi\": \"hi\",\n",
        "    \"French\": \"fr\",\n",
        "    \"German\": \"de\",\n",
        "    \"Spanish\": \"es\"\n",
        "}\n",
        "\n",
        "# Available direct translation models (HuggingFace supports these)\n",
        "available_pairs = {\n",
        "    (\"hi\", \"en\"): \"Helsinki-NLP/opus-mt-hi-en\",\n",
        "    (\"en\", \"hi\"): \"Helsinki-NLP/opus-mt-en-hi\",\n",
        "    (\"en\", \"fr\"): \"Helsinki-NLP/opus-mt-en-fr\",\n",
        "    (\"fr\", \"en\"): \"Helsinki-NLP/opus-mt-fr-en\",\n",
        "    (\"en\", \"de\"): \"Helsinki-NLP/opus-mt-en-de\",\n",
        "    (\"de\", \"en\"): \"Helsinki-NLP/opus-mt-de-en\",\n",
        "    (\"en\", \"es\"): \"Helsinki-NLP/opus-mt-en-es\",\n",
        "    (\"es\", \"en\"): \"Helsinki-NLP/opus-mt-es-en\"\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WqFJt1F6dYKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to Load MarianMT Model and Tokenizer from Hugging Face\n",
        "def load_model(model_name):\n",
        "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "    model = MarianMTModel.from_pretrained(model_name)\n",
        "    return tokenizer, model"
      ],
      "metadata": {
        "id": "px7uJ5N_fr32"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Translate input text using the specified MarianMT model\n",
        "def run_translation(text, model_name):\n",
        "    tokenizer, model = load_model(model_name)\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
        "    translated = model.generate(**inputs)\n",
        "    return tokenizer.decode(translated[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "ykX_-PPdfr1X"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main translation logic handles direct and two-step translations based on available models\n",
        "\n",
        "def translate_text(text, src_lang_name, tgt_lang_name):\n",
        "    src_lang = language_codes.get(src_lang_name)\n",
        "    tgt_lang = language_codes.get(tgt_lang_name)\n",
        "\n",
        "    if not src_lang or not tgt_lang:\n",
        "        return \"One or both selected languages are not supported.\"\n",
        "\n",
        "    model_key = (src_lang, tgt_lang)\n",
        "\n",
        "    if model_key in available_pairs:\n",
        "        print(f\"Using direct model: {available_pairs[model_key]}\")\n",
        "        return run_translation(text, available_pairs[model_key])\n",
        "\n",
        "    elif (src_lang != \"en\") and (tgt_lang != \"en\"):\n",
        "        # Use two-step: source â†’ English â†’ target\n",
        "        to_en_key = (src_lang, \"en\")\n",
        "        from_en_key = (\"en\", tgt_lang)\n",
        "\n",
        "        if to_en_key in available_pairs and from_en_key in available_pairs:\n",
        "            print(f\" Using two-step: {to_en_key} then {from_en_key}\")\n",
        "            english_text = run_translation(text, available_pairs[to_en_key])\n",
        "            final_output = run_translation(english_text, available_pairs[from_en_key])\n",
        "            return final_output\n",
        "        else:\n",
        "            return \"Two-step translation path not available.\"\n",
        "\n",
        "    else:\n",
        "        return \"Sorry, no model available for that translation direction.\""
      ],
      "metadata": {
        "id": "0DFbdvcCfry6"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "# print(translate_text(\"à¤®à¥à¤à¥‡ à¤–à¤¾à¤¨à¤¾ à¤ªà¤¸à¤‚à¤¦ à¤¹à¥ˆ\", \"Hindi\", \"French\"))"
      ],
      "metadata": {
        "id": "NCQn4Ra1frvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(translate_text(\"I hate books\", \"English\", \"Hindi\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAr6ycEletzN",
        "outputId": "69c543f6-3e63-4025-cd80-8d733e6ffb4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” Using direct model: Helsinki-NLP/opus-mt-en-hi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "à¤®à¥ˆà¤‚ à¤ªà¥à¤¸à¥à¤¤à¤•à¥‹à¤‚ à¤¸à¥‡ à¤¨à¤«à¤°à¤¤ à¤¹à¥ˆ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok transformers sentencepiece langdetect -q\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMPBU8Bkjh4h",
        "outputId": "899b07b6-4acf-47af-d300-6ccfd6b5d015"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 30XEouoDhpqdqrS1WfWSmCy5Jct_5iA5vFpq4htpTjP9aniNa\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al_B9qGWl8lU",
        "outputId": "1e7d320c-8582-495d-e987-14d8bbbda4a9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Launch Streamlit with Ngrok"
      ],
      "metadata": {
        "id": "vSvOyDOeqQnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Launching Streamlit App via Ngrok Tunnel for Google Colab\n",
        "# Write the entire Streamlit app code to a temporary Python file\n",
        "# This is required because Streamlit runs apps from .py scripts,\n",
        "# and Colab doesn't support native Streamlit execution.\n",
        "# We'll run this script using ngrok to serve the app publicly.\n",
        "\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# Write your Streamlit code to a temporary file\n",
        "with open(\"main_app.py\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "import streamlit as st\n",
        "from langdetect import detect\n",
        "from transformers import MarianTokenizer, MarianMTModel\n",
        "\n",
        "language_codes = {\n",
        "    \"English\": \"en\",\n",
        "    \"Hindi\": \"hi\",\n",
        "    \"French\": \"fr\",\n",
        "    \"German\": \"de\",\n",
        "    \"Spanish\": \"es\"\n",
        "}\n",
        "\n",
        "available_pairs = {\n",
        "    (\"hi\", \"en\"): \"Helsinki-NLP/opus-mt-hi-en\",\n",
        "    (\"en\", \"hi\"): \"Helsinki-NLP/opus-mt-en-hi\",\n",
        "    (\"en\", \"fr\"): \"Helsinki-NLP/opus-mt-en-fr\",\n",
        "    (\"fr\", \"en\"): \"Helsinki-NLP/opus-mt-fr-en\",\n",
        "    (\"en\", \"de\"): \"Helsinki-NLP/opus-mt-en-de\",\n",
        "    (\"de\", \"en\"): \"Helsinki-NLP/opus-mt-de-en\",\n",
        "    (\"en\", \"es\"): \"Helsinki-NLP/opus-mt-en-es\",\n",
        "    (\"es\", \"en\"): \"Helsinki-NLP/opus-mt-es-en\"\n",
        "}\n",
        "\n",
        "def load_model(model_name):\n",
        "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "    model = MarianMTModel.from_pretrained(model_name)\n",
        "    return tokenizer, model\n",
        "\n",
        "def run_translation(text, model_name):\n",
        "    tokenizer, model = load_model(model_name)\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
        "    translated = model.generate(**inputs)\n",
        "    return tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "\n",
        "def translate_text(text, src_lang_name, tgt_lang_name):\n",
        "    src_lang = language_codes.get(src_lang_name)\n",
        "    tgt_lang = language_codes.get(tgt_lang_name)\n",
        "\n",
        "    if not src_lang or not tgt_lang:\n",
        "        return \"One or both selected languages are not supported.\"\n",
        "\n",
        "    model_key = (src_lang, tgt_lang)\n",
        "\n",
        "    if model_key in available_pairs:\n",
        "        return run_translation(text, available_pairs[model_key])\n",
        "\n",
        "    elif (src_lang != \"en\") and (tgt_lang != \"en\"):\n",
        "        to_en_key = (src_lang, \"en\")\n",
        "        from_en_key = (\"en\", tgt_lang)\n",
        "\n",
        "        if to_en_key in available_pairs and from_en_key in available_pairs:\n",
        "            english_text = run_translation(text, available_pairs[to_en_key])\n",
        "            return run_translation(english_text, available_pairs[from_en_key])\n",
        "        else:\n",
        "            return \"Two-step translation path not available.\"\n",
        "\n",
        "    else:\n",
        "        return \"No model available for the selected translation direction.\"\n",
        "\n",
        "# Streamlit UI\n",
        "st.set_page_config(page_title=\"Translator\", layout=\"centered\")\n",
        "st.title(\" Multilingual Text Translator\")\n",
        "\n",
        "text = st.text_area(\"Enter text to translate:\", height=100)\n",
        "src_lang = st.selectbox(\"From Language\", list(language_codes.keys()))\n",
        "tgt_lang = st.selectbox(\"To Language\", list(language_codes.keys()))\n",
        "\n",
        "if st.button(\"Translate\"):\n",
        "    if text.strip() == \"\":\n",
        "        st.warning(\"Please enter some text.\")\n",
        "    else:\n",
        "        output = translate_text(text, src_lang, tgt_lang)\n",
        "        st.success(\"Translated Text:\")\n",
        "        st.write(output)\n",
        "\"\"\")\n",
        "\n",
        "# Run the app via Streamlit and expose via ngrok\n",
        "!streamlit run main_app.py &>/content/log.txt &  # Run in background\n",
        "public_url = ngrok.connect(addr=\"8501\")\n",
        "print(\" Streamlit app is live at:\", public_url)\n"
      ],
      "metadata": {
        "id": "XWlOs0ECfe_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41318c8f-f347-4659-de30-f6b7ca4ac4cd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Streamlit app is live at: NgrokTunnel: \"https://494d3ad862e0.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7Zsxg0OxjUC",
        "outputId": "8f641bcb-50f3-45be-fbb4-17f9a2ed4f9b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m905.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m620.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Semantic similarity"
      ],
      "metadata": {
        "id": "gYhQ5JKoy7Xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Load a sentence embedding model\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "# Example translations\n",
        "\n",
        "your_translation = translate_text(\"à¤¨à¤®à¤¸à¥à¤¤à¥‡ à¤†à¤ª à¤•à¥ˆà¤¸à¥‡ à¤¹à¥ˆ\", \"Hindi\", \"English\")\n",
        "google_translation = \"hello how are you\"\n",
        "\n",
        "# Get sentence embeddings\n",
        "embedding1 = model.encode(your_translation, convert_to_tensor=True)\n",
        "embedding2 = model.encode(google_translation, convert_to_tensor=True)\n",
        "\n",
        "# Compute cosine similarity\n",
        "similarity_score = util.pytorch_cos_sim(embedding1, embedding2).item()\n",
        "\n",
        "print(f\"Semantic Similarity Score: {similarity_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0unsAOqMlCBE",
        "outputId": "449b501b-1f7a-43a8-c8a1-7bcb2d3e1838"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using direct model: Helsinki-NLP/opus-mt-hi-en\n",
            "Semantic Similarity Score: 0.8049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JeAvmOwJyhFi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}